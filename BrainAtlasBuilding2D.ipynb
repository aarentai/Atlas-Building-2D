{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from Packages.RegistrationFunc import *\n",
    "from Packages.SplitEbinMetric import *\n",
    "from Packages.GeoPlot import *\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data I/O convention\n",
    "\n",
    "### Read\n",
    "Shape of input_tensor.nhdr is `[w, h, 2]`, and Shape of input_mask.nhdr is `[w, h]`\n",
    "```\n",
    "input_tensor = np.transpose(sitk.GetArrayFromImage(sitk.ReadImage(path)),(2,1,0))\n",
    "input_mask = np.transpose(sitk.GetArrayFromImage(sitk.ReadImage(path)),(1,0))\n",
    "```\n",
    "input_tensor.shape is `[2, h, w]`, and input_mask.shape is `[h, w]`\n",
    "### Write\n",
    "output_tensor.shape is `[2, h, w]`, and output_mask.shape is `[h, w]`\n",
    "```\n",
    "output_tensor = sitk.WriteImage(sitk.GetImageFromArray(np.transpose(output_tensor,(2,1,0)), path)\n",
    "output_mask = sitk.WriteImage(sitk.GetImageFromArray(np.transpose(output_tensor,(2,1,0)), path)\n",
    "```\n",
    "Shape of output_tensor.nhdr is `[w, h, 2]`, and Shape of output_mask.nhdr is `[w, h]`\n",
    "\n",
    "### Note\n",
    "`sitk.WriteImage(sitk.GetImageFromArray())` and `sitk.GetArrayFromImage(sitk.ReadImage(path))` is a pair of inverse operation, and you can see there is no inconsistence with regards to the dimension issue.\n",
    "```\n",
    "output_tensor = np.zeros((12,34,56,78))\n",
    "sitk.WriteImage(sitk.GetImageFromArray(output_tensor), path)\n",
    "input_tensor = sitk.GetArrayFromImage(sitk.ReadImage(path))\n",
    "print(input_tensor)\n",
    "'(12,34,56,78)'\n",
    "```\n",
    "\n",
    "## Data dim convention\n",
    "\n",
    "Make sure you follow the conventions below to make the algorithm consistent.\n",
    "- Tensor fields: All the tensor fields variables by default are of size `[h, w, 2, 2]`, making the last two dimensions index metric matrix, to comply pytorch. In my code, arguments and the outputs of all functions meet this requirement. \n",
    "- Diffeomorphisms: All the diffeo variables by default are of size `[2, h, w]`.\n",
    "- Masks: All the mask variables by default are of size `[h, w]`, when it comes to `torch.einsum()`, you can use `.unsqueeze(0)` for temporary.\n",
    "\n",
    "## Data plotting convention\n",
    "\n",
    "To avoid the `x` and `y` ambiguity in indexing and ploting, naming the first two dimension in `[h, w, 2, 2]` in the order of `x`, `y` is the best choice! \n",
    "- When indexing the array, `x` indexes row and `y` indexes column, the way I typically do and the way how matplotlib plot the 2d image. \n",
    "- When plotting the tensors, matplotlib would rotate the array counterclockwise by 90 degrees. So the vertical axis is `y` and horizontal axis is `x`, which is also consistent with our knowledge in drawing the Cartesian coordinate system. Fortunately, Kirs' code has already done in this way, like the ellipse(x, y). \n",
    "\n",
    "\n",
    "## Algorithm caveat\n",
    "- In energy calculation, only use the binary mask provided by Kris, rather than a weighted map, which will change the alpha field applied to the tensor field previously and result in geodesic misgoing.\n",
    "- Both metric matching and mean calculating should be implemented on the inverse of the original DTI tensor field, since the geodesics are running on the inverse of the tensor field.\n",
    "- When accumulating the diffeomorphisms, always remember the order of accumulation of phi and its inverse is different.\n",
    "```\n",
    "phi_acc = compose_function(phi_acc, phi)\n",
    "psi_inv_acc = compose_function(phi_inv, psi_inv_acc)\n",
    "```\n",
    "- When an error like below is raised, it's probably caused by a large epsilon, so the composed tensor field is no longer positive definite everywhere.\n",
    "```\n",
    "cholesky_cpu: For batch 0: U(1,1) is zero, singular U.\n",
    "```\n",
    "- `a` in `Squared_distance_Ebin(g0, g1, a, mask)`, `get_karcher_mean(G, a)`, `get_geo(g0, g1, a, Tpts)`, `inv_RieExp_extended(g0, g1, a)`, `Rie_Exp_extended(g0, u, a)`, `Rie_Exp(g0, u, a)`, `inv_RieExp(g0, g1, a)` equals to the reciprocal of dimension, `1/dim`, namely the last entry of tensor field's shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_pullback(phi, g):\n",
    "#     input: phi.shape = [2, h, w]; g.shape = [h, w, 2, 2]\n",
    "#     output: shape = [h, w, 2, 2]\n",
    "    g = g.permute(2,3,0,1)\n",
    "    idty = get_idty(*g.shape[-2:])\n",
    "    d_phi = get_jacobian_matrix(phi - idty) + torch.einsum(\"ij,mn->ijmn\", [torch.eye(2,dtype=torch.double),\n",
    "                                                                           torch.ones(g.shape[-2:],dtype=torch.double)])\n",
    "    g_phi = compose_function(g, phi)\n",
    "    return torch.einsum(\"ijmn,ikmn,klmn->mnjl\",[d_phi, g_phi, d_phi])\n",
    "\n",
    "\n",
    "def energy_ebin(phi, g0, g1, f0, f1, sigma, lambd, mask): \n",
    "#     input: phi.shape = [2, h, w]; g0/g1/f0/f1.shape = [h, w, 2, 2]; sigma/lambd = scalar; mask.shape = [1, h, w]\n",
    "#     output: scalar\n",
    "    phi_star_g1 = phi_pullback(phi, g1)\n",
    "    phi_star_f1 = phi_pullback(phi, f1)\n",
    "    E1 = sigma*Squared_distance_Ebin(f0, phi_star_f1, lambd, mask)\n",
    "    E2 = Squared_distance_Ebin(g0, phi_star_g1, lambd, mask)\n",
    "    return E1 + E2\n",
    "\n",
    "\n",
    "def energy_L2(phi, g0, g1, f0, f1, sigma, mask): \n",
    "#     input: phi.shape = [2, h, w]; g0/g1/f0/f1.shape = [h, w, 2, 2]; sigma/lambd = scalar; mask.shape = [1, h, w]\n",
    "#     output: scalar\n",
    "    phi_star_g1 = phi_pullback(phi, g1)\n",
    "    phi_star_f1 = phi_pullback(phi, f1)\n",
    "    E1 = sigma*torch.einsum(\"ij...,kij->\", (f0 - phi_star_f1)**2, mask.unsqueeze(0))\n",
    "    E2 = torch.einsum(\"ij...,kij->\", (g0 - phi_star_g1)**2, mask.unsqueeze(0))\n",
    "    return E1 + E2\n",
    "\n",
    "\n",
    "def laplace_inverse(u):\n",
    "#     input: u.shape = [2, h, w]\n",
    "#     output: shape = [2, h, w]\n",
    "    size_h, size_w = u.shape[-2:]\n",
    "    shape = u.shape\n",
    "    idty = get_idty(size_h, size_w).numpy()\n",
    "    lap = 4. - 2.*(np.cos(2.*np.pi*idty[0]/size_w) + np.cos(2.*np.pi*idty[1]/size_h))\n",
    "    lap[0,0] = 1.\n",
    "    lapinv = 1./lap\n",
    "    lap[0,0] = 0.\n",
    "    lapinv[0,0] = 1.\n",
    "    \n",
    "    u = u.detach().numpy()\n",
    "    fx = np.fft.fftn(u[0])\n",
    "    fy = np.fft.fftn(u[1])\n",
    "    fx *= lapinv\n",
    "    fy *= lapinv\n",
    "    vx = torch.from_numpy(np.real(np.fft.ifftn(fx)))\n",
    "    vy = torch.from_numpy(np.real(np.fft.ifftn(fy)))\n",
    "    \n",
    "    return torch.stack((vx,vy))\n",
    "\n",
    "\n",
    "def vis_squared_distance_ebin(g0, g1, a):  \n",
    "    inv_g0 = get_inverse(g0)\n",
    "    inv_g0_g1 = torch.einsum(\"ik...,kj...->...ij\",[inv_g0, g1]) \n",
    "    trK0square = trKsquare(g0, g1) - torch.log(get_det(inv_g0_g1) + 1e-25)**2/2 \n",
    "    theta = torch.min((trK0square/a + 1e-25).sqrt()/4, torch.tensor([np.pi],dtype=torch.double))\n",
    "    \n",
    "    det_g0 = g0[0, 0] * g0[1, 1] - g0[0, 1] * g0[1, 0] + 1e-25\n",
    "    det_g1 = g1[0, 0] * g1[1, 1] - g1[0, 1] * g1[1, 0] + 1e-25\n",
    "    \n",
    "    alpha, beta = det_g0.pow(1/4), det_g1.pow(1/4)\n",
    "    E = 16*a*(alpha**2 - 2*alpha*beta*torch.cos(theta) + beta**2)\n",
    "    fig = plt.figure()\n",
    "    im = plt.imshow(E)\n",
    "    fig.colorbar(im)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "    return 0\n",
    "\n",
    "\n",
    "def GetSITKImageFromNP(npimg, has_component_data=False):\n",
    "  # If RGB or tensor data etc, set has_component_data to True so that last dimension is not\n",
    "  # transposed.\n",
    "  # This assumes that the component data is in the last dimension.\n",
    "  # TODO fix this assumption to work for component data in first dimension as well\n",
    "  # Currently works for 2D and 3D images\n",
    "  if has_component_data:\n",
    "    transpose_tuple=(1,0,2)\n",
    "    if len(npimg.shape) == 4:\n",
    "      transpose_tuple=(2,1,0,3)    \n",
    "    return sitk.GetImageFromArray(np.transpose(npimg,transpose_tuple))\n",
    "  else:\n",
    "    transpose_tuple=(1,0)\n",
    "    if len(npimg.shape) == 3:\n",
    "      transpose_tuple=(2,1,0)           \n",
    "    return sitk.GetImageFromArray(np.transpose(npimg, transpose_tuple))\n",
    "\n",
    "        \n",
    "def metric_matching(gi, gm, height, width, mask, iter_num, epsilon, sigma):\n",
    "    phi_inv = get_idty(height, width)\n",
    "    phi = get_idty(height, width)\n",
    "    idty = get_idty(height, width)\n",
    "    idty.requires_grad_()\n",
    "    f0 = torch.eye(2, dtype=torch.double).repeat(height, width,1,1)\n",
    "    f1 = torch.eye(2, dtype=torch.double).repeat(height, width,1,1)\n",
    "    \n",
    "    for j in range(iter_num):\n",
    "        phi_actsg0 = phi_pullback(phi_inv, gi)\n",
    "        phi_actsf0 = phi_pullback(phi_inv, f0)\n",
    "        E = energy_ebin(idty, phi_actsg0, gm, phi_actsf0, f1, sigma,0.5, mask) \n",
    "        E.backward()\n",
    "        v = - laplace_inverse(idty.grad)\n",
    "        with torch.no_grad():\n",
    "            psi =  idty + epsilon*v  \n",
    "            psi[0][psi[0]>width-1]=width-1\n",
    "            psi[1][psi[1]>height-1]=height-1\n",
    "            psi[psi<0]=0\n",
    "            psi_inv =  idty - epsilon*v\n",
    "            psi_inv[0][psi_inv[0]>width-1]=width-1\n",
    "            psi_inv[1][psi_inv[1]>height-1]=height-1\n",
    "            psi_inv[psi_inv<0]=0\n",
    "            phi = compose_function(psi, phi)\n",
    "            phi_inv = compose_function(phi_inv, psi_inv)\n",
    "            idty.grad.data.zero_()\n",
    "    gi = phi_pullback(phi_inv, gi)\n",
    "    return gi, phi, phi_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = [103818,111312]\n",
    "rescale_thresh = [4e7, 1e7]\n",
    "height, width = 145,174\n",
    "sample_num = len(file_name)\n",
    "tensor_lin_list, tensor_met_list, mask_list, mask_thresh_list = [], [], [], []\n",
    "mask_union = torch.zeros(height, width).double()\n",
    "phi_inv_acc_list, phi_acc_list, energy_list = [], [], []\n",
    "\n",
    "for s in range(len(file_name)):\n",
    "#     read tensor and mask files\n",
    "    tensor_np = sitk.GetArrayFromImage(sitk.ReadImage('Data/Brains/{}_thresh_tensors.nhdr'.format(file_name[s])))\n",
    "    mask_np = sitk.GetArrayFromImage(sitk.ReadImage('Data/Brains/{}_filt_mask.nhdr'.format(file_name[s])))\n",
    "    tensor_lin_list.append(torch.from_numpy(tensor_np).double().permute(1,0,2))\n",
    "#     create union of masks\n",
    "    mask_union += torch.from_numpy(mask_np).double().permute(1,0)\n",
    "    mask_list.append(torch.from_numpy(mask_np).double().permute(1,0))\n",
    "#     rearrange tensor_lin to tensor_met\n",
    "    tensor_met_zeros = torch.zeros(height,width,2,2,dtype=torch.double)\n",
    "    tensor_met_zeros[:,:,0,0] = tensor_lin_list[s][0]\n",
    "    tensor_met_zeros[:,:,0,1] = tensor_lin_list[s][1]\n",
    "    tensor_met_zeros[:,:,1,0] = tensor_lin_list[s][1]\n",
    "    tensor_met_zeros[:,:,1,1] = tensor_lin_list[s][2]\n",
    "#     balance the background and subject by rescaling\n",
    "    tensor_met_list.append(torch.inverse(tensor_met_zeros))\n",
    "    mask_thresh_list.append(torch.where(torch.det(tensor_met_list[s])>rescale_thresh[s], 1/torch.det(tensor_met_list[s]), 5e-7))\n",
    "    tensor_met_list[s] = torch.einsum('ij...,kij->ij...', tensor_met_list[s], mask_thresh_list[s].unsqueeze(0))\n",
    "#     initialize the accumulative diffeomorphism\n",
    "    phi_inv_acc_list.append(get_idty(height, width))\n",
    "    phi_acc_list.append(get_idty(height, width))\n",
    "    energy_list.append([])\n",
    "    \n",
    "mask_union[mask_union>0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sci/hdai/Projects/Atlas2D/Packages/SplitEbinMetric.py:270: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370141920/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  Ind_inRange = (theta < 0).nonzero().reshape(-1)  ## G[i] is in the range of the exponential map at gm\n"
     ]
    }
   ],
   "source": [
    "for i in range(401):\n",
    "    G = torch.stack(tuple(tensor_met_list))\n",
    "    a = 0.5\n",
    "    atlas = get_karcher_mean(G, a)\n",
    "\n",
    "    lambd, sigma, epsilon, iter_num = 0.5, 0, 1e0, 1\n",
    "    phi_inv_list, phi_list = [], []\n",
    "    for s in range(sample_num):\n",
    "        energy_list[s].append(torch.einsum(\"ij...,kij->\",[(tensor_met_list[s] - atlas)**2, mask_union.unsqueeze(0)]).item())\n",
    "        tensor_met_list[s], phi, phi_inv = metric_matching(tensor_met_list[s], atlas, height, width, mask_union, iter_num, epsilon, sigma)\n",
    "        phi_inv_list.append(phi_inv)\n",
    "        phi_list.append(phi)\n",
    "        phi_inv_acc_list[s] = compose_function(phi_inv_acc_list[s], phi_inv_list[s])\n",
    "        phi_acc_list[s] = compose_function(phi_list[s], phi_acc_list[s])\n",
    "        mask_list[s] = compose_function(mask_list[s], phi_inv_list[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_2d_tensors(atlas, scale=1e3, title=\"g0\", margin=0.05, dpi=20)\n",
    "\n",
    "# tl = torch.from_numpy(sitk.GetArrayFromImage(sitk.ReadImage('brain103818_111312_noweight_thresh_tensors.nhdr'))).double().permute(2,1,0)\n",
    "# tm = torch.zeros(height,width,2,2,dtype=torch.double)\n",
    "# tm[:,:,0,0] = tl[0]\n",
    "# tm[:,:,0,1] = tl[1]\n",
    "# tm[:,:,1,0] = tl[1]\n",
    "# tm[:,:,1,1] = tl[2]\n",
    "# # show_2d_tensors(tm, scale=1e3, title=\"g0\", margin=0.05, dpi=20)\n",
    "\n",
    "# # print(torch.norm((tm-atlas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_2d_tensors(tm, scale=1e3, title=\"g0\", margin=0.05, dpi=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis_tensors_kris(tl, 'title', save_file=False, filename='', mask=None,scale=1e3,opacity=0.5, show_axis_labels=True, ax=None,zorder=1,stride=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis_ellipses(tl, title=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# atlas_lin = np.zeros((3,height,width))\n",
    "# mask_acc = np.zeros((height,width))\n",
    "\n",
    "# for s in range(sample_num):\n",
    "#     sio.savemat('BrainAtlas/brain{}_phi_inv.mat'.format(file_name[s]), {'diffeo': phi_inv_acc_list[s].detach().numpy()})\n",
    "#     sio.savemat('BrainAtlas/brain{}_phi.mat'.format(file_name[s]), {'diffeo': phi_acc_list[s].detach().numpy()})\n",
    "#     sio.savemat('BrainAtlas/brain{}_energy.mat'.format(file_name[s]), {'energy': energy_list[s]})\n",
    "#     plt.plot(energy_list[s])\n",
    "#     mask_acc += mask_list[s].numpy()\n",
    "    \n",
    "# atlas_lin[0]=atlas[:,:,0,0]\n",
    "# atlas_lin[1]=atlas[:,:,0,1]\n",
    "# atlas_lin[2]=atlas[:,:,1,1]\n",
    "# sitk.WriteImage(sitk.GetImageFromArray(np.transpose(atlas_lin,(2,1,0))), 'BrainAtlas/atlas_tensors.nhdr')\n",
    "# sio.savemat('BrainAtlas/mask_acc.mat', {'mask': mask_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j = 1\n",
    "# idty = compose_function(phi_inv_acc_list[j], phi_acc_list[j])\n",
    "# plot_diffeo(idty, step_size=2, show_axis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
