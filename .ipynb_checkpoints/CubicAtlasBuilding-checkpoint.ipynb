{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from Packages.RegistrationFunc import *\n",
    "from Packages.SplitEbinMetric import *\n",
    "from Packages.GeoPlot import *\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_pullback(phi, g):\n",
    "#     input: phi.shape = [2, h, w]; g.shape = [h, w, 2, 2]\n",
    "#     output: shape = [h, w, 2, 2]\n",
    "    g = g.permute(2,3,0,1)\n",
    "    idty = get_idty(*g.shape[-2:])\n",
    "    d_phi = get_jacobian_matrix(phi - idty) + torch.einsum(\"ij,mn->ijmn\", [torch.eye(2,dtype=torch.double),\n",
    "                                                                           torch.ones(g.shape[-2:],dtype=torch.double)])\n",
    "    g_phi = compose_function(g, phi)\n",
    "    return torch.einsum(\"ijmn,ikmn,klmn->mnjl\",[d_phi, g_phi, d_phi])\n",
    "\n",
    "\n",
    "def energy_ebin(phi, g0, g1, f0, f1, sigma, lambd, mask): \n",
    "#     input: phi.shape = [2, h, w]; g0/g1/f0/f1.shape = [h, w, 2, 2]; sigma/lambd = scalar; mask.shape = [1, h, w]\n",
    "#     output: scalar\n",
    "    phi_star_g1 = phi_pullback(phi, g1)\n",
    "    phi_star_f1 = phi_pullback(phi, f1)\n",
    "    E1 = sigma*Squared_distance_Ebin(f0, phi_star_f1, lambd, mask)\n",
    "    E2 = Squared_distance_Ebin(g0, phi_star_g1, lambd, mask)\n",
    "    return E1 + E2\n",
    "\n",
    "\n",
    "def energy_L2(phi, g0, g1, f0, f1, sigma, mask): \n",
    "#     input: phi.shape = [2, h, w]; g0/g1/f0/f1.shape = [h, w, 2, 2]; sigma/lambd = scalar; mask.shape = [1, h, w]\n",
    "#     output: scalar\n",
    "    phi_star_g1 = phi_pullback(phi, g1)\n",
    "    phi_star_f1 = phi_pullback(phi, f1)\n",
    "    E1 = sigma*torch.einsum(\"ij...,kij->\", (f0 - phi_star_f1)**2, mask)\n",
    "    E2 = torch.einsum(\"ij...,kij->\", (g0 - phi_star_g1)**2, mask)\n",
    "    return E1 + E2\n",
    "\n",
    "\n",
    "def laplace_inverse(u):\n",
    "#     input: u.shape = [2, h, w]\n",
    "#     output: shape = [2, h, w]\n",
    "    size_h, size_w = u.shape[-2:]\n",
    "    shape = u.shape\n",
    "    idty = get_idty(size_h, size_w).numpy()\n",
    "    lap = 4. - 2.*(np.cos(2.*np.pi*idty[0]/size_w) + np.cos(2.*np.pi*idty[1]/size_h))\n",
    "    lap[0,0] = 1.\n",
    "    lapinv = 1./lap\n",
    "    lap[0,0] = 0.\n",
    "    lapinv[0,0] = 1.\n",
    "    \n",
    "    u = u.detach().numpy()\n",
    "    fx = np.fft.fftn(u[0])\n",
    "    fy = np.fft.fftn(u[1])\n",
    "    fx *= lapinv\n",
    "    fy *= lapinv\n",
    "    vx = torch.from_numpy(np.real(np.fft.ifftn(fx)))\n",
    "    vy = torch.from_numpy(np.real(np.fft.ifftn(fy)))\n",
    "    \n",
    "    return torch.stack((vx,vy))\n",
    "\n",
    "\n",
    "def vis_squared_distance_ebin(g0, g1, a):  \n",
    "    inv_g0 = get_inverse(g0)\n",
    "    inv_g0_g1 = torch.einsum(\"ik...,kj...->...ij\",[inv_g0, g1]) \n",
    "    trK0square = trKsquare(g0, g1) - torch.log(get_det(inv_g0_g1) + 1e-25)**2/2 \n",
    "    theta = torch.min((trK0square/a + 1e-25).sqrt()/4, torch.tensor([np.pi],dtype=torch.double))\n",
    "    \n",
    "    det_g0 = g0[0, 0] * g0[1, 1] - g0[0, 1] * g0[1, 0] + 1e-25\n",
    "    det_g1 = g1[0, 0] * g1[1, 1] - g1[0, 1] * g1[1, 0] + 1e-25\n",
    "    \n",
    "    alpha, beta = det_g0.pow(1/4), det_g1.pow(1/4)\n",
    "    E = 16*a*(alpha**2 - 2*alpha*beta*torch.cos(theta) + beta**2)\n",
    "    fig = plt.figure()\n",
    "    im = plt.imshow(E)\n",
    "    fig.colorbar(im)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "    return 0\n",
    "\n",
    "\n",
    "def GetSITKImageFromNP(npimg, has_component_data=False):\n",
    "  # If RGB or tensor data etc, set has_component_data to True so that last dimension is not\n",
    "  # transposed.\n",
    "  # This assumes that the component data is in the last dimension.\n",
    "  # TODO fix this assumption to work for component data in first dimension as well\n",
    "  # Currently works for 2D and 3D images\n",
    "  if has_component_data:\n",
    "    transpose_tuple=(1,0,2)\n",
    "    if len(npimg.shape) == 4:\n",
    "      transpose_tuple=(2,1,0,3)    \n",
    "    return sitk.GetImageFromArray(np.transpose(npimg,transpose_tuple))\n",
    "  else:\n",
    "    transpose_tuple=(1,0)\n",
    "    if len(npimg.shape) == 3:\n",
    "      transpose_tuple=(2,1,0)           \n",
    "    return sitk.GetImageFromArray(np.transpose(npimg, transpose_tuple))\n",
    "\n",
    "        \n",
    "def metric_matching(gi, gm, height, width, mask, iter_num, epsilon, sigma):\n",
    "    phi_inv = get_idty(height, width)\n",
    "    phi = get_idty(height, width)\n",
    "    idty = get_idty(height, width)\n",
    "    idty.requires_grad_()\n",
    "    f0 = torch.eye(2, dtype=torch.double).repeat(height, width,1,1)\n",
    "    f1 = torch.eye(2, dtype=torch.double).repeat(height, width,1,1)\n",
    "    \n",
    "    for j in range(iter_num):\n",
    "        phi_actsg0 = phi_pullback(phi_inv, gi)\n",
    "        phi_actsf0 = phi_pullback(phi_inv, f0)\n",
    "        E = energy_ebin(idty, phi_actsg0, gm, phi_actsf0, f1, sigma,0.5, mask.unsqueeze(0)) \n",
    "        E.backward()\n",
    "        v = - laplace_inverse(idty.grad)\n",
    "        with torch.no_grad():\n",
    "            psi =  idty + epsilon*v  \n",
    "            psi[0][psi[0]>width-1]=width-1\n",
    "            psi[1][psi[1]>height-1]=height-1\n",
    "            psi[psi<0]=0\n",
    "            psi_inv =  idty - epsilon*v\n",
    "            psi_inv[0][psi_inv[0]>width-1]=width-1\n",
    "            psi_inv[1][psi_inv[1]>height-1]=height-1\n",
    "            psi_inv[psi_inv<0]=0\n",
    "            phi = compose_function(psi, phi)\n",
    "            phi_inv = compose_function(phi_inv, psi_inv)\n",
    "            idty.grad.data.zero_()\n",
    "    gi = phi_pullback(phi_inv, gi)\n",
    "    return gi, phi, phi_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In energy calculation, only use the binary mask, rather than weighted map, which will change the alpha field applied to the tensor field previously and result in geodesic going wrong.\n",
    "2. Both metric matching and mean calculating should be implemented on the inverse of the original DTI tensor field, since the geodesics are running on the inverse of the tensor field.\n",
    "3. When accumulating of diffeomorphism, always remember the order of accumulation of phi and its inverse is different.\n",
    "    * phi_acc = compose_function(phi_acc, phi)\n",
    "    * psi_inv_acc = compose_function(phi_inv, psi_inv_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = [1,2,4,6]\n",
    "height, width = 100,100\n",
    "sample_num = len(file_name)\n",
    "tensor_lin_list, tensor_met_list, mask_list, mask_thresh_list = [], [], [], []\n",
    "mask_union = torch.zeros(height, width).double()\n",
    "phi_inv_acc_list, phi_acc_list, energy_list = [], [], []\n",
    "\n",
    "for s in range(len(file_name)):\n",
    "#     read tensor and mask files\n",
    "    tensor_np = sitk.GetArrayFromImage(sitk.ReadImage('Data/Cubic/cubic{}_scaled_tensors.nhdr'.format(file_name[s])))\n",
    "    mask_np = sitk.GetArrayFromImage(sitk.ReadImage('Data/Cubic/cubic{}_filt_mask.nhdr'.format(file_name[s])))\n",
    "    tensor_lin_list.append(torch.from_numpy(tensor_np).double().permute(2,1,0))\n",
    "#     create union of masks\n",
    "    mask_union += torch.from_numpy(mask_np).double().permute(1,0)\n",
    "    mask_list.append(torch.from_numpy(mask_np).double().permute(1,0))\n",
    "#     rearrange tensor_lin to tensor_met\n",
    "    tensor_met_zeros = torch.zeros(height,width,2,2,dtype=torch.double)\n",
    "    tensor_met_zeros[:,:,0,0] = tensor_lin_list[s][0]\n",
    "    tensor_met_zeros[:,:,0,1] = tensor_lin_list[s][1]\n",
    "    tensor_met_zeros[:,:,1,0] = tensor_lin_list[s][1]\n",
    "    tensor_met_zeros[:,:,1,1] = tensor_lin_list[s][2]\n",
    "#     balance the background and subject by rescaling\n",
    "    tensor_met_list.append(torch.inverse(tensor_met_zeros))\n",
    "    mask_thresh_list.append(torch.where(torch.det(tensor_met_list[s])>1e7, 1/torch.det(tensor_met_list[s]), 5e-3))\n",
    "    tensor_met_list[s] = torch.einsum('ij...,kij->ij...', tensor_met_list[s], mask_thresh_list[s].unsqueeze(0))\n",
    "#     initialize the accumulative diffeomorphism\n",
    "    phi_inv_acc_list.append(get_idty(height, width))\n",
    "    phi_acc_list.append(get_idty(height, width))\n",
    "    energy_list.append([])    \n",
    "    \n",
    "mask_union[mask_union>0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sci/hdai/IPMIbugfree/Packages/SplitEbinMetric.py:268: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729006826/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  Ind_inRange = (theta < 0).nonzero().reshape(-1)  ## G[i] is in the range of the exponential map at gm\n"
     ]
    }
   ],
   "source": [
    "for i in range(201):\n",
    "    G = torch.stack(tuple(tensor_met_list))\n",
    "    a = 0.5\n",
    "    atlas = get_karcher_mean(G, a)\n",
    "\n",
    "    lambd, sigma, epsilon, iter_num = 0.5, 0, 5e0, 1\n",
    "    phi_inv_list, phi_list = [], []\n",
    "    for s in range(sample_num):\n",
    "        energy_list[s].append(torch.einsum(\"ij...,kij->\",[(tensor_met_list[s] - atlas)**2, mask_union.unsqueeze(0)]).item())\n",
    "        tensor_met_list[s], phi, phi_inv = metric_matching(tensor_met_list[s], atlas, height, width, mask_union, iter_num, epsilon, sigma)\n",
    "        phi_inv_list.append(phi_inv)\n",
    "        phi_list.append(phi)\n",
    "        phi_inv_acc_list[s] = compose_function(phi_inv_acc_list[s], phi_inv_list[s])\n",
    "        phi_acc_list[s] = compose_function(phi_list[s], phi_acc_list[s])\n",
    "        mask_list[s] = compose_function(mask_list[s], phi_inv_list[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7945e-11, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# show_2d_tensors(atlas, scale=1e3, title=\"g0\", margin=0.05, dpi=20)\n",
    "\n",
    "tl = torch.from_numpy(sitk.GetArrayFromImage(sitk.ReadImage('orig_result.nhdr'))).double().permute(2,1,0)\n",
    "tm = torch.zeros(height,width,2,2,dtype=torch.double)\n",
    "tm[:,:,0,0] = tl[0]\n",
    "tm[:,:,0,1] = tl[1]\n",
    "tm[:,:,1,0] = tl[1]\n",
    "tm[:,:,1,1] = tl[2]\n",
    "\n",
    "print(torch.norm((tm-atlas)/atlas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# atlas_lin = np.zeros((height,width,3))\n",
    "# mask_acc = np.zeros((height,width))\n",
    "\n",
    "# for s in range(sample_num):\n",
    "#     sio.savemat('Cubic1246Atlas/cubic{}_phi_inv.mat'.format(file_name[s]), {'diffeo': phi_inv_acc_list[s].detach().numpy()})\n",
    "#     sio.savemat('Cubic1246Atlas/cubic{}_phi.mat'.format(file_name[s]), {'diffeo': phi_acc_list[s].detach().numpy()})\n",
    "#     sio.savemat('Cubic1246Atlas/cubic{}_energy.mat'.format(file_name[s]), {'energy': energy_list[s]})\n",
    "#     plt.plot(energy_list[s])\n",
    "#     mask_acc += mask_list[s].numpy()\n",
    "    \n",
    "# atlas_lin[:,:,0]=atlas[:,:,0,0]\n",
    "# atlas_lin[:,:,1]=atlas[:,:,0,1]\n",
    "# atlas_lin[:,:,2]=atlas[:,:,1,1]\n",
    "# sitk.WriteImage(GetSITKImageFromNP(atlas_lin, has_component_data=True), 'Cubic1246TemplateEbin/atlas_tensors.nhdr')\n",
    "# sio.savemat('Cubic1246TemplateEbin/mask_acc.mat', {'mask': mask_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j = 1\n",
    "# idty = compose_function(phi_inv_acc_list[j], phi_acc_list[j])\n",
    "# plot_diffeo(idty, step_size=2, show_axis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
